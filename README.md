# sequence-tagging
sequence tagging

### bert_model
从 https://huggingface.co/models 下载bert-base-chinese模型，解压在pretrained_models下

bert-base-chinese目录结构如下：
```
bert-base-chinese/
├── config.json
├── pytorch_model.bin
└── vocab.txt
```